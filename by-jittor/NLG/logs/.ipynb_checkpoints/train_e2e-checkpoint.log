==================================================================================================== - 2025-05-26 21:34:18,577 - log
        - random_seed : 2025 - 2025-05-26 21:34:18,578 - log
        - lr : 0.0002 - 2025-05-26 21:34:18,578 - log
        - weight_decay : 0.01 - 2025-05-26 21:34:18,578 - log
        - correct_bias : False - 2025-05-26 21:34:18,578 - log
        - adam_epislon : 1e-06 - 2025-05-26 21:34:18,578 - log
        - no_decay_bias : False - 2025-05-26 21:34:18,578 - log
        - adam_beta1 : 0.9 - 2025-05-26 21:34:18,578 - log
        - adam_beta2 : 0.999 - 2025-05-26 21:34:18,578 - log
        - scheduler : linear - 2025-05-26 21:34:18,578 - log
        - max_step : None - 2025-05-26 21:34:18,578 - log
        - max_epoch : 5 - 2025-05-26 21:34:18,578 - log
        - warmup_step : 500 - 2025-05-26 21:34:18,578 - log
        - i_steps : 0 - 2025-05-26 21:34:18,578 - log
        - i_lrs : 0.00025 - 2025-05-26 21:34:18,578 - log
        - train_data : ./data/e2e/train.jsonl - 2025-05-26 21:34:18,578 - log
        - valid_data : ./data/e2e/valid.jsonl - 2025-05-26 21:34:18,578 - log
        - train_batch_size : 2 - 2025-05-26 21:34:18,578 - log
        - valid_batch_size : 1 - 2025-05-26 21:34:18,578 - log
        - grad_acc : 2 - 2025-05-26 21:34:18,578 - log
        - clip : 0.0 - 2025-05-26 21:34:18,578 - log
        - seq_len : 64 - 2025-05-26 21:34:18,578 - log
        - model_card : gpt2.sm - 2025-05-26 21:34:18,578 - log
        - init_checkpoint : ./pretrained_checkpoints/gpt2-pytorch_model.bin - 2025-05-26 21:34:18,578 - log
        - fp16 : False - 2025-05-26 21:34:18,578 - log
        - log_interval : 100 - 2025-05-26 21:34:18,578 - log
        - eval_interval : 2000 - 2025-05-26 21:34:18,578 - log
        - save_interval : 1000 - 2025-05-26 21:34:18,578 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-05-26 21:34:18,578 - log
        - lora_dim : 4 - 2025-05-26 21:34:18,578 - log
        - lora_alpha : 32 - 2025-05-26 21:34:18,578 - log
        - obj : clm - 2025-05-26 21:34:18,578 - log
        - lora_dropout : 0.1 - 2025-05-26 21:34:18,578 - log
        - label_smooth : 0.1 - 2025-05-26 21:34:18,578 - log
        - roll_interval : -1 - 2025-05-26 21:34:18,579 - log
        - roll_lr : 1e-05 - 2025-05-26 21:34:18,579 - log
        - roll_step : 100 - 2025-05-26 21:34:18,579 - log
        - eval_epoch : 1 - 2025-05-26 21:34:18,579 - log
        - device : cuda - 2025-05-26 21:34:18,579 - log
==================================================================================================== - 2025-05-26 21:34:18,579 - log
--------------------------------------------------train-------------------------------------------------- - 2025-05-26 21:34:18,579 - log
